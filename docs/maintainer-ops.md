---
title: "Maintainer-Ops"
version: 1.2.2
tags: [meta]
---

# Maintainer-Ops

Dieses Memo b√ºndelt alle internen Abl√§ufe f√ºr den Betrieb von
**ZEITRISS 4.2.6**. Haltet die Schritte strikt ein, damit QA, Releases und
Plattform-Listings synchron bleiben.

## Wissensspeicher & Grundsetup

Der vollst√§ndige Datensatz f√ºr GPTs und Custom-AIs besteht aus folgenden
Bestandteilen. Die Wissensspeicher-Slots sind f√ºr `README.md` plus die 19 Runtime-Module
reserviert - der Masterprompt bleibt im Systemfeld (oder als erste
Chatnachricht), Repo-Hilfsdateien bleiben offline:

1. **Masterprompt:** `meta/masterprompt_v6.md` (Local-Uncut 4.2.6, Systemfeld
   bzw. erste Nachricht). Die Vorversion liegt als Referenz in
   `meta/archive/masterprompt_v6_legacy.md`.
2. **README:** `README.md` als Wissensmodul f√ºr Einstieg, Einleitung und
   Betriebsnavigation hochladen.
3. **Runtime-Module:** Exakt die unten aufgelisteten 19 Markdown-Dateien aus
   den Runtime-Verzeichnissen (`core/`, `characters/`, `gameplay/`, `systems/`).
4. **Nicht hochladen:** `master-index.json` bleibt ein repo-internes
   Steuerdokument f√ºr Setup-Automation und QA.

> **Slot-Kontrolle:** Nach jedem Upload, Export oder Speicherstand pr√ºfen, ob
> alle 20 Wissensmodule (README + 19 Runtime-Module) geladen sind.
> Fehlende oder veraltete Module unverz√ºglich nachfordern und erneut hochladen.

| Kategorie    | Datei |
|--------------|-------|
| **characters** | `characters/ausruestung-cyberware.md` |
|              | `characters/charaktererschaffung-grundlagen.md` |
|              | `characters/charaktererschaffung-optionen.md` |
|              | `characters/zustaende.md` |
|              | `characters/hud-system.md` |
| **core**     | `core/wuerfelmechanik.md` |
|              | `core/zeitriss-core.md` |
|              | `core/sl-referenz.md` |
| **gameplay** | `gameplay/fahrzeuge-konflikte.md` |
|              | `gameplay/kampagnenstruktur.md` |
|              | `gameplay/kampagnenuebersicht.md` |
|              | `gameplay/kreative-generatoren-begegnungen.md` |
|              | `gameplay/kreative-generatoren-missionen.md` |
|              | `gameplay/massenkonflikte.md` |
| **systems**  | `systems/currency/cu-waehrungssystem.md` |
|              | `systems/gameflow/cinematic-start.md` |
|              | `systems/gameflow/speicher-fortsetzung.md` |
|              | `systems/kp-kraefte-psi.md` |
|              | `systems/toolkit-gpt-spielleiter.md` |

### Runtimes & Tests au√üerhalb des Wissensspeichers

- `internal/runtime/runtime-stub-routing-layer.md`, `runtime.js`, Skripte und
  Tools verbleiben ausschlie√ülich im Repo.
- **Repo-Agent:innen verpflichten sich, jede best√§tigte Laufzeit√§nderung
  unmittelbar als Regelwerk, Prozessbeschreibung oder Pseudocode in den
  Wissensspeicher-Modulen zu spiegeln** (z. B. README, Runtime-Handb√ºcher).
  Nur so erreichen produktive GPTs denselben Funktionsumfang ohne lokale
  Skripte.
- Halte einen Abgleich im QA-Journal fest (`internal/qa/logs/`), sobald du eine
  Laufzeit√§nderung spiegelst. Notiere Commit-ID, Datum und die Module, die den
  Pseudocode/Regeltext enthalten.
- Nutze lokale Runtimes weiter f√ºr Entwicklung und Tests; dokumentiere
  Abweichungen zwischen Skript und Wissensbasis, bis sie synchronisiert sind.
  Maintainer:innen pr√ºfen im Review, ob dieser Wissensspiegel vorliegt, bevor
  sie Plattform-Runtimes aktualisieren.

### Spiegelhinweis f√ºr Laufzeit√§nderungen

- Pr√ºft nach jedem Merge, ob `runtime.js` oder andere Offline-Laufzeitdateien
  angepasst wurden.
- √úbertragt best√§tigte √Ñnderungen manuell in die produktive Runtime der
  Plattform (MyGPT/Store-GPT) gem√§√ü Abschnitt
  ["Spiegelprozess nach QA-Freigabe"](#spiegelprozess-nach-qa-freigabe).
  Grundlage ist stets der durch den Repo-Agenten bereits vollst√§ndig
  gespiegelte Wissensstand.
- Dokumentiert den Mirror im QA-Log inkl. Commit-ID, Datum und Hinweis darauf,
  welches Wissensspeicher-Modul die Pseudocode-/Regelspiegelung enth√§lt, damit
  Foreshadow-Log und andere Laufzeitfeatures ingame verf√ºgbar bleiben.

Hinweise zum Rollenmodell (Repo-Agent, MyGPT, Beta-GPT, Kodex) stehen in
`AGENTS.md`. Eine Dokumenten-Landkarte mit Zielgruppen und √úbergabepunkten
findest du im Abschnitt
[‚ÄûDokumenten-Landkarte"](setup-guide.md#dokumenten-landkarte) des Setup-Guides. Diese
Datei konzentriert sich auf ausf√ºhrbare Abl√§ufe.

**Grundsatz:** Alle QA-L√§ufe finden ausschlie√ülich im OpenAI-MyGPT-Beta-Klon
statt. Erst nach einer gr√ºnen Abnahme werden Store-GPT und OpenWebUI-Instanzen mit genau diesem Stand gespiegelt; separate Optimierungen f√ºr andere
Plattformen sind derzeit nicht vorgesehen.

## QA-Plattformstrategie

- **Referenz-Plattform:** Der Beta-Klon von **ZEITRISS [Ver. 4.2.6]** auf
  OpenAI-MyGPT ist die einzige Instanz f√ºr aktive QA-L√§ufe. Alle
  Regressionstests, Acceptance-Smokes und Save/Load-Pr√ºfungen werden hier
  durchgef√ºhrt und anschlie√üend im QA-Log abgelegt.
- **Freigabebedingung:** Erst nachdem der Beta-Klon die QA als "gr√ºn" meldet
  und Codex die Nachverfolgung im QA-Fahrplan geschlossen hat, darf der
  Wissensstand auf weitere Plattformen gespiegelt werden.
- **Spiegelroutine:** Store-GPT und OpenWebUI-Installationen erhalten
  ausschlie√ülich den freigegebenen Stand. Abweichungen oder Erg√§nzungen werden
  nicht eigenst√§ndig ausprobiert, sondern als Findings an Codex zur√ºckgegeben.
- **Dokumentation:** Jede Spiegelung wird mit Datum, Zielplattform und Verweis
  auf den passenden QA-Log-Abschnitt dokumentiert. Nur so bleibt nachvollziehbar,
  welche Plattform welchen Stand l√§dt.

## QA-Artefakte & Nachverfolgung

- [QA-Fahrplan 2025](../internal/qa/plans/ZEITRISS-qa-fahrplan-2025.md) -
  priorisierte Ma√ünahmenliste mit Status-Tracking und Commit-Verweisen.
- [QA-Audit 2025](../internal/qa/audits/ZEITRISS-qa-audit-2025.md) -
  Zusammenfassung der Testl√§ufe inklusive Bewertungsmatrix.
- [Beta-QA-Log 2025](../internal/qa/logs/2025-beta-qa-log.md) - vollst√§ndige
  Copy-&-Paste-Protokolle aus Beta-GPT/MyGPT mit Nachverfolgung.
- [Tester-Playtest-Briefing](./qa/tester-playtest-briefing.md) -
  Standardauftrag f√ºr Beta-/MyGPT-L√§ufe inklusive Acceptance-Smoke.

Stand 2025-06-22: Deepcheck-Sessions 2025-06-11-2025-06-16 abgeschlossen,
Ma√ünahmenbl√∂cke (Save, HUD/UX, PvP/Arena) auf ‚úÖ gesetzt; siehe QA-Fahrplan &
QA-Log 2025-06-22.

Verkn√ºpfe jede QA-Ma√ünahme in PR-Beschreibungen mit dem passenden Log-Abschnitt
und aktualisiere Audit sowie Fahrplan nach dem Merge. Aktuelle QA-L√§ufe finden
ausschlie√ülich im OpenAI-MyGPT-Beta statt. Der Standardprompt aus dem
Tester-Playtest-Briefing l√§sst den GPT den gesamten QA-Lauf autonom simulieren
und liefert strukturierte `ISSUE`-, `L√∂sungsvorschlag`-, `To-do`- und
`N√§chste Schritte`-Bl√∂cke f√ºr Codex. Store-GPT und OpenWebUI-Instanzen
spiegeln erst nach erfolgreicher MyGPT-Abnahme denselben Stand ohne zus√§tzliche
Plattformoptimierung.

### Solo-Maintainer-Workflow (Stand 2025)

- **Arbeitsaufteilung:** Aktuell betreut eine Person das Projekt. Alle
  Repositoriumsaufgaben laufen √ºber Codex (Repo-Agent). Operative QA- und
  Playtest-Sessions erfolgen ausschlie√ülich im Beta-GPT, indem ein vorbereiteter
  Testprompt in den Chat gelegt wird.
- **√úbergabeformat:** Die Beta-GPT-Antwort b√ºndelt den vollst√§ndigen QA-Run samt
  `ISSUE`-, `L√∂sungsvorschlag`-, `To-do`- und `N√§chste Schritte`-Bl√∂cken. Diese
  Ausgabe wird unver√§ndert in ein neues Anweisungsfenster f√ºr Codex kopiert.
  Codex √ºbertr√§gt daraus die erforderlichen √Ñnderungen in Repo-Dateien,
  Fahrpl√§ne und QA-Logs.
- **Nachweise:** Der Testprompt deckt Acceptance-Smokes, Regressionen und
  Spiegel-Checks ab. Codex dokumentiert die Ergebnisse in den Maintainer- und
  QA-Dokumenten und referenziert die jeweiligen Chatlogs.
- **Erweiterbarkeit:** Sollte sich das Team vergr√∂√üern, bleibt dieser Ablauf
  g√ºltig, bis eine alternative Rollenaufteilung dokumentiert wird. Zus√§tzliche
  Maintainer:innen richten eigene Beta-Klone ein und liefern ihre Ergebnisse in
  derselben Form an Codex.

### Standardbefehl f√ºr Repo-Agent:innen

Nutze f√ºr Folgeauftr√§ge immer dieselbe Kurzform, damit Codex den QA-Fahrplan
Schritt f√ºr Schritt abarbeitet und nur Repo-Artefakte aktualisiert:

> `Codex, arbeite bitte den QA-Fahrplan (internal/qa/plans/ZEITRISS-qa-fahrplan-2025.md)
> Schritt f√ºr Schritt ab und setze die genannten Ma√ünahmen direkt im Repo um.
> Spiegle jede Laufzeit√§nderung in den Wissensmodulen (README, Systems-Module)
> und halte die Trennung zwischen Runtime-Stubs (runtime.js, routing-layer) und
> den GPT-Laufzeitdateien strikt ein.`

Der Zusatz stellt klar, dass lokale Hilfsskripte (z. B. `runtime.js`) nur f√ºr
Tests dienen und alle ingame-relevanten Inhalte in die Wissensmodule geh√∂ren.

## Plattform-Workflows

### OpenAI MyGPT & GPT-Store
1. Einen Custom GPT **ZEITRISS [Ver. 4.2.6]** erstellen.
2. Einen Pitch mit max. 300 Zeichen hinterlegen, z. B. "Zeitreise-RPG mit
   Kodex-HUD, explosiven W√ºrfeln und Solo/Coop-Balancing. Keine echten Daten,
   mehr Infos auf https://zeitriss.org/".
3. `meta/masterprompt_v6.md` (Local-Uncut 4.2.6) vollst√§ndig in das
   Masterprompt-Feld kopieren und speichern. Die Legacy-Fassung liegt bei
   Bedarf in `meta/archive/masterprompt_v6_legacy.md`.
4. `README.md` und alle 19 Runtime-Module (ohne Runtime-Stub) in den
   Wissensspeicher hochladen. `master-index.json` nicht hochladen.
5. Den GPT direkt klonen und **ZEITRISS [Ver. 4.2.6] beta** nennen.
6. S√§mtliche QA-Sessions ausschlie√ülich im Beta-Klon durchf√ºhren und Verhalten
   im QA-Log dokumentieren.
7. QA und Publishing erst freigeben, wenn die Chat-Historie keine
   personenbezogenen Daten enth√§lt.
8. Nach bestandener QA den Stand in den Haupt-GPT √ºbertragen und erst danach
   das Store-Listing aktualisieren. Vermerkt die Spiegelung mit Verweis auf den
   QA-Log-Eintrag des gr√ºnen Runs.

### Lokaler Betrieb (Ollama + OpenWebUI)
1. Nach erfolgreicher MyGPT-Abnahme Ollama mit dem gew√ºnschten Modell
   installieren und OpenWebUI lokal verbinden.
2. Entweder `./scripts/setup-openwebui.sh` ausf√ºhren oder manuell
   Masterprompt plus 20 Wissensmodule (README + 19 Runtime-Module) importieren.
3. Es erfolgen derzeit keine dedizierten lokalen Optimierungen; pr√ºfe nur, ob
   der freigegebene Stand geladen wird, und notiere Abweichungen im QA-Log.

### Spiegelprozess nach QA-Freigabe

1. Pr√ºfe im QA-Fahrplan, dass der relevante Abschnitt als abgeschlossen markiert und mit Commit-ID
   versehen ist.
2. Exportiere den Wissensspeicher aus dem MyGPT-Beta-Klon (README + 19 Runtime-Module).
3. √úbertrage den Stand unver√§ndert in den produktiven MyGPT und dokumentiere
   Datum sowie QA-Log-Referenz.
4. Spiegele denselben Export im Anschluss auf Store-GPT und lokale
   OpenWebUI-Instanzen in dieser Reihenfolge. Jede Plattform erh√§lt exakt
   denselben Datei-Satz.
5. Erg√§nze im QA-Log einen kurzen Spiegelvermerk (Plattform, Datum,
   verantwortliche Person). Abweichungen werden als neue Findings festgehalten.

### Sync-Checks & Beispielworkflow

- Nach jedem freigegebenen Update best√§tigen, dass MyGPT und Store-GPT denselben
  Stand f√ºhren (Masterprompt + README + 19 Runtime-Module) und den Release
  anschlie√üend auf OpenWebUI spiegeln.
- Sicherstellen, dass exakt 20 Wissensmodule geladen sind; der Runtime-Stub
  bleibt au√üen vor.
- F√ºr Schnelltests die Checkliste aus
  [Acceptance-Smoke](./qa/tester-playtest-briefing.md#acceptance-smoke-checkliste)
  nutzen und Ergebnisse hier protokollieren.
- Detailablauf f√ºr Uploads siehe Abschnitt "Beispielworkflow" im README; dort
  stehen die Datei-Checks, die beim Laden kontrolliert werden.

## Go-Live-Checkliste (Build 4.2.6)
Vor der Spiegelung auf produktive Plattformen sind die folgenden Schritte
abzuschlie√üen und im QA-Log zu dokumentieren:

1. **Repository-Pr√ºfungen**
   - `make lint` (inkl. doppeltem Runtime-Lint, Doc-Link- und Umlaut-Checks sowie
     Markdownlint f√ºr Wissensmodule)
   - `make test`
   - `npm run test:acceptance` (Mission-5-Badge-/HUD-Snapshots gegen Golden File)
   - `npm run test:hud`
   - `npm run test:debrief`
   - `npm run test:comms`
   Alle L√§ufe m√ºssen ohne Fehler durchlaufen; Warnungen werden im Commit-Log
   vermerkt.
2. **Dokumentationsabgleich**
   - Audit, Fahrplan und Maintainer-Ops auf denselben Stand bringen (Versionen
     pr√ºfen, offene Fragen schlie√üen, QA-Referenzen erg√§nzen).
   - README-Sektion "QA-Artefakte & Nachverfolgung" auf aktuelle Links testen.
3. **QA-Log & Freigabe**
  - Acceptance-Smoke gegen
    [Acceptance-Smoke](./qa/tester-playtest-briefing.md#acceptance-smoke-checkliste)
    abhaken und den Lauf im QA-Log mit Datum, Plattform und Build-ID
    protokollieren.
   - Offene Punkte im QA-Log schlie√üen oder vertagen (inkl. Verweis auf den
     verantwortlichen Commit).
4. **Spiegelentscheidung**
   - Erst wenn alle obigen Schritte gr√ºn sind, Beta-GPT ‚Üí Produktiv-GPT ‚Üí
     Store-GPT ‚Üí lokale OpenWebUI-Instanzen spiegeln.
   - Jede Spiegelung mit Datum, Plattform und QA-Log-Verweis festhalten.

## QA-Loop & Speicherst√§nde
Halte f√ºr QA und Save/Load-Checks den √úbergabeprozess in
`CONTRIBUTING.md#beta-gpt-qa-uebergaben` ein. Erg√§nzend gilt:

### Beta-GPT & Playtests
1. Klone nach jedem Release-Kandidaten den produktiven MyGPT zu
   **ZEITRISS [Ver. 4.2.6] beta**.
2. Starte Playtests ausschlie√ülich im Beta-Klon, f√ºge den Auftrag aus
   `docs/qa/tester-playtest-briefing.md` in die erste Chat-Nachricht ein und lasse
   den GPT den kompletten QA-Run ohne weitere Eingriffe simulieren.
3. Pr√ºfe, dass die Antwort die geforderten `ISSUE`-, `L√∂sungsvorschlag`-,
   `To-do`- und `N√§chste Schritte`-Bl√∂cke je Befund enth√§lt, und √ºbertrage sie
   gesammelt und unver√§ndert an Codex (Repo-Agent). Codex erstellt daraus
   Tickets, dokumentiert Freigaben und aktualisiert QA-/Maintainer-Docs.
4. Notiere im QA-Log, welcher Beta-GPT-Prompt verwendet wurde, damit sp√§tere
   Regressionen denselben Ablauf nachvollziehen k√∂nnen.
5. Synchronisiere den Wissensspeicher des produktiven MyGPT sowie weiterer
   Plattformen erst, nachdem Codex die QA als gr√ºn markiert hat.

### √úbergabe an Codex & Dokumentation
1. Exportiere nach jeder Beta-GPT-Session das vollst√§ndige Chatlog (inklusive
   Debug-Ausgaben) und sende es unver√§ndert an Codex. Die vom GPT erzeugten
   `ISSUE`-, `L√∂sungsvorschlag`-, `To-do`- und `N√§chste Schritte`-Bl√∂cke ersetzen
   separate Stichpunktlisten.
2. Markiere im Log klar die Plattform (Standard: MyGPT Beta auf openai.com),
   den Build-Stand und den verwendeten Wissensspeicher.
3. Notiere in deiner √úbergabe, ob Uploads, Save/Load-Checks oder
   Plattformspiegelungen bereits erfolgt sind. Codex √ºbernimmt daraufhin die
   Pflege der Dateien `internal/qa/logs/2025-beta-qa-log.md`,
   `internal/qa/plans/ZEITRISS-qa-fahrplan-2025.md` und
   `internal/qa/audits/ZEITRISS-qa-audit-2025.md` im
   Repo.
4. Nachdem Codex die QA-Dokumente aktualisiert und alle Findings abgearbeitet
   hat, spiegelst du den freigegebenen Stand auf Store-GPT und lokale OpenWebUI-Instanzen. Dokumentiere Abweichungen ausschlie√ülich dann, wenn sie
   vom MyGPT-Referenzlauf abweichen.

### Zus√§tzliche QA-Pflichten
1. Plane mindestens drei komplette Durchl√§ufe im MyGPT-Beta ein; weitere
   Plattformen erhalten denselben Stand ohne eigenst√§ndige QA-Schleifen.
2. In jeder Session Save/Load pr√ºfen: `saveGame({...})` ausgeben lassen, lokal
   sichern, neuen Chat √∂ffnen und den Reimport testen.
3. Accessibility-Dialoge (HUD-Erkl√§rung, Offline-Hinweise) und
   HQ-Briefing-Schleifen abgleichen.
4. Acceptance-Smoke-Checklist aus `docs/qa/tester-playtest-briefing.md`
   erg√§nzen und Abweichungen festhalten. Smoketests laufen bei jedem Merge
   automatisch im Repo; dokumentiert erg√§nzende Befunde weiterhin im QA-Log.
5. Falls die GitHub-Action `scripts/smoke.sh` mit einem `ECONNRESET` beim
   Artefakt-Upload scheitert, Job erneut ansto√üen. Der Fehler entsteht beim
   Finalisieren des Uploads und erfordert inhaltlich keine Anpassung am Repo.

### Regressionstest-Zeitplan 2025

- **Q1 2025 (19.03.2025 - Acceptance-Smoke-Abgleich)**
  - Schwerpunkt: Vollst√§ndiger Regressionstest (Build 4.2.6) mit Save/Load.
  - Status: ‚úÖ abgeschlossen.
  - QA-Log: `internal/qa/logs/2025-beta-qa-log.md`, Abschnitt 2025-03-19.
- **Q2 2025 (09.-13.06.2025)**
  - Schwerpunkt: Spiegelprozesse, Save/Load-Regression und Upload-Checks.
  - Status: üóìÔ∏è geplant.
  - QA-Log: Eintrag folgt nach Lauf.
- **Q3 2025 (08.-12.09.2025)**
  - Schwerpunkt: Arena-Gro√üteam-Regression, HUD-Badges und Timer.
  - Status: üóìÔ∏è geplant.
  - QA-Log: Eintrag folgt nach Lauf.
- **Q4 2025 (08.-12.12.2025)**
  - Schwerpunkt: Jahresabschluss-Regression mit Spiegelkontrolle.
  - Status: üóìÔ∏è geplant.
  - QA-Log: Eintrag folgt nach Lauf.

> Aktualisiere Termine bei Verschiebungen unmittelbar im QA-Fahrplan und hier;
> Spiegelplattformen nur nach gr√ºner MyGPT-Abnahme synchronisieren.

## Systemgrenzen (Reminder)
- KI-Spielleitung kann keine Dateien schreiben oder Repos ver√§ndern;
  Speicherst√§nde nur via Copy & Paste.
- Save-Funktionen laufen ausschlie√ülich √ºber das HQ. Missionen lassen sich
  abbrechen, aber nicht zwischen-speichern.
- MyGPT und Store-GPT laufen online ohne Webtool. Ollama/OpenWebUI bleiben vollst√§ndig offline und ohne Webtools.
- DSGVO-konforme Chats sicherstellen: keine realen personenbezogenen Daten
  posten, keine unverschl√ºsselten Log-Transkripte.

## Release-Checkliste
- Versionierung nach **MAJOR.MINOR.PATCH**. `CHANGELOG.md`, `README.md`,
  `master-index.json` und Store-Listing synchron aktualisieren.
- Rechtliche Hinweise pr√ºfen (`docs/trademark.md`, `LICENSE`,
  Markenverweise im README).
- `make lint`, `make test` und `scripts/smoke.sh` ausf√ºhren; Ergebnisse im
  QA-Log vermerken.
- Vor Freigabe sicherstellen, dass auf jeder Plattform exakt 20
  Wissensmodule (README + 19 Runtime-Module) plus Masterprompt vorliegen -
  ohne den Runtime-Stub und ohne `master-index.json` im Wissensspeicher.
- Erst releasen, wenn der Beta-GPT auf MyGPT gr√ºn meldet. Danach Store-GPT aktualisieren und den freigegebenen Stand lokal in
  OpenWebUI spiegeln. Siehe
  `CONTRIBUTING.md#beta-gpt-qa-uebergaben` f√ºr die √úbergabe an Codex.
