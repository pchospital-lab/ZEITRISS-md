---
title: "Maintainer-Ops"
version: 1.2.1
tags: [meta]
---

# Maintainer-Ops

Dieses Memo b√ºndelt alle internen Abl√§ufe f√ºr den Betrieb von
**ZEITRISS¬†4.2.2**. Haltet die Schritte strikt ein, damit QA, Releases und
Plattform-Listings synchron bleiben.

## Wissensspeicher & Grundsetup

Der vollst√§ndige Datensatz f√ºr GPTs und Custom-AIs besteht aus folgenden
Bestandteilen und wird in jeder Zielplattform in den Wissensspeicher geladen.
Die 20 verf√ºgbaren Slots sind ausschlie√ülich f√ºr diese Dateien reserviert ‚Äì
Repo-Hilfsdateien bleiben offline:

1. **Masterprompt:** `meta/masterprompt_v6.md` (Systemfeld bzw. erste Nachricht; optional zus√§tzlich als Wissensspeicher-Eintrag).
2. **Dokumentationsanker:** `README.md` und `master-index.json`.
3. **Runtime-Module:** Exakt die unten aufgelisteten 18 Markdown-Dateien aus den Runtime-Verzeichnissen.

> **Slot-Kontrolle:** Nach jedem Upload, Export oder Speicherstand pr√ºfen, ob alle 20 Module geladen sind. Fehlende oder veraltete
> Module unverz√ºglich nachfordern und erneut hochladen.

| Kategorie    | Datei |
|--------------|-------|
| **characters** | `characters/ausruestung-cyberware.md` |
|              | `characters/charaktererschaffung.md` |
|              | `characters/cyberware-und-bioware.md` |
|              | `characters/psi-talente.md` |
|              | `characters/zustaende-hud-system.md` |
| **core**     | `core/wuerfelmechanik.md` |
|              | `core/zeitriss-core.md` |
| **gameplay** | `gameplay/fahrzeuge-konflikte.md` |
|              | `gameplay/kampagnenstruktur.md` |
|              | `gameplay/kampagnenuebersicht.md` |
|              | `gameplay/kreative-generatoren-begegnungen.md` |
|              | `gameplay/kreative-generatoren-missionen.md` |
|              | `gameplay/massenkonflikte.md` |
| **systems**  | `systems/currency/cu-waehrungssystem.md` |
|              | `systems/gameflow/cinematic-start.md` |
|              | `systems/gameflow/speicher-fortsetzung.md` |
|              | `systems/kp-kraefte-psi.md` |
|              | `systems/toolkit-gpt-spielleiter.md` |

Optional kann der Masterprompt zus√§tzlich als Wissensspeicher-Eintrag
gesichert werden, um lange Sessions stabil zu halten.

### Runtimes & Tests au√üerhalb des Wissensspeichers

- `systems/runtime-stub-routing-layer.md`, `runtime.js`, Skripte und Tools verbleiben ausschlie√ülich im Repo.
- **Repo-Agent:innen verpflichten sich, jede best√§tigte Laufzeit√§nderung unmittelbar als Regelwerk, Prozessbeschreibung oder
  Pseudocode in den Wissensspeicher-Modulen zu spiegeln** (z.‚ÄØB. README, Runtime-Handb√ºcher). Nur so erreichen produktive GPTs
  denselben Funktionsumfang ohne lokale Skripte.
- Halte einen Abgleich im QA-Journal fest (`internal/qa/logs/`), sobald du eine Laufzeit√§nderung spiegelst. Notiere Commit-ID,
  Datum und die Module, die den Pseudocode/Regeltext enthalten.
- Nutze lokale Runtimes weiter f√ºr Entwicklung und Tests; dokumentiere Abweichungen zwischen Skript und Wissensbasis, bis sie
  synchronisiert sind. Maintainer:innen pr√ºfen im Review, ob dieser Wissensspiegel vorliegt, bevor sie Plattform-Runtimes
  aktualisieren.

### Spiegelhinweis f√ºr Laufzeit√§nderungen

- Pr√ºft nach jedem Merge, ob `runtime.js` oder andere Offline-Laufzeitdateien angepasst wurden.
- √úbertragt best√§tigte √Ñnderungen manuell in die produktive Runtime der Plattform (MyGPT/Store-GPT) gem√§√ü Abschnitt
  [‚ÄûSpiegelprozess nach QA-Freigabe‚Äú](#spiegelprozess-nach-qa-freigabe). Grundlage ist stets der durch den Repo-Agenten bereits
  vollst√§ndig gespiegelte Wissensstand.
- Dokumentiert den Mirror im QA-Log inkl. Commit-ID, Datum und Hinweis darauf, welches Wissensspeicher-Modul die
  Pseudocode-/Regelspiegelung enth√§lt, damit Foreshadow-Log und andere Laufzeitfeatures ingame verf√ºgbar bleiben.

Hinweise zum Rollenmodell (Repo-Agent, MyGPT, Beta-GPT, Kodex) stehen in
`AGENTS.md`. Eine Dokumenten-Landkarte mit Zielgruppen und √úbergabepunkten findest du im
Abschnitt [‚ÄûDokumenten-Landkarte‚Äú](../README.md#dokumenten-landkarte) des README. Diese Datei
konzentriert sich auf ausf√ºhrbare Abl√§ufe.

**Grundsatz:** Alle QA-L√§ufe finden ausschlie√ülich im OpenAI-MyGPT-Beta-Klon
statt. Erst nach einer gr√ºnen Abnahme werden Store-GPT, Proton LUMO und lokale
Instanzen mit genau diesem Stand gespiegelt; separate Optimierungen f√ºr andere
Plattformen sind derzeit nicht vorgesehen.

## QA-Plattformstrategie

- **Referenz-Plattform:** Der Beta-Klon von **ZEITRISS [Ver.¬†4.2.2]** auf OpenAI-MyGPT ist die einzige
  Instanz f√ºr aktive QA-L√§ufe. Alle Regressionstests, Acceptance-Smokes und
  Save/Load-Pr√ºfungen werden hier durchgef√ºhrt und anschlie√üend im QA-Log
  abgelegt.
- **Freigabebedingung:** Erst nachdem der Beta-Klon die QA als ‚Äûgr√ºn‚Äú meldet
  und Codex die Nachverfolgung im QA-Fahrplan geschlossen hat, darf der
  Wissensstand auf weitere Plattformen gespiegelt werden.
- **Spiegelroutine:** Store-GPT, Proton LUMO und lokale Installationen erhalten
  ausschlie√ülich den freigegebenen Stand. Abweichungen oder Erg√§nzungen werden
  nicht eigenst√§ndig ausprobiert, sondern als Findings an Codex zur√ºckgegeben.
- **Dokumentation:** Jede Spiegelung wird mit Datum, Zielplattform und Verweis
  auf den passenden QA-Log-Abschnitt dokumentiert. Nur so bleibt nachvollziehbar,
  welche Plattform welchen Stand l√§dt.

### Solo-Maintainer-Workflow (Stand 2025)

- **Arbeitsaufteilung:** Aktuell betreut eine Person das Projekt. Alle
  Repositoriumsaufgaben laufen √ºber Codex (Repo-Agent). Operative QA- und
  Playtest-Sessions erfolgen ausschlie√ülich im Beta-GPT, indem ein vorbereiteter
  Testprompt in den Chat gelegt wird.
- **√úbergabeformat:** Die Beta-GPT-Antwort b√ºndelt den vollst√§ndigen QA-Run samt
  `ISSUE`-, `L√∂sungsvorschlag`-, `To-do`- und `N√§chste Schritte`-Bl√∂cken. Diese
  Ausgabe wird unver√§ndert in ein neues Anweisungsfenster f√ºr Codex kopiert.
  Codex √ºbertr√§gt daraus die erforderlichen √Ñnderungen in Repo-Dateien,
  Fahrpl√§ne und QA-Logs.
- **Nachweise:** Der Testprompt deckt Acceptance-Smokes, Regressionen und
  Spiegel-Checks ab. Codex dokumentiert die Ergebnisse in den Maintainer- und
  QA-Dokumenten und referenziert die jeweiligen Chatlogs.
- **Erweiterbarkeit:** Sollte sich das Team vergr√∂√üern, bleibt dieser Ablauf
  g√ºltig, bis eine alternative Rollenaufteilung dokumentiert wird. Zus√§tzliche
  Maintainer:innen richten eigene Beta-Klone ein und liefern ihre Ergebnisse in
  derselben Form an Codex.

### Standardbefehl f√ºr Repo-Agent:innen

Nutze f√ºr Folgeauftr√§ge immer dieselbe Kurzform, damit Codex den QA-Fahrplan Schritt f√ºr Schritt abarbeitet und nur Repo-Artefakte aktualisiert:

> `Codex, arbeite bitte den QA-Fahrplan (internal/qa/plans/ZEITRISS-qa-fahrplan-2025.md) Schritt f√ºr Schritt ab und setze die genannten Ma√ünahmen direkt im Repo um. Spiegle jede Laufzeit√§nderung in den Wissensmodulen (README, Systems-Module) und halte die Trennung zwischen Runtime-Stubs (runtime.js, routing-layer) und den GPT-Laufzeitdateien strikt ein.`

Der Zusatz stellt klar, dass lokale Hilfsskripte (z.‚ÄØB. `runtime.js`) nur f√ºr Tests dienen und alle ingame-relevanten Inhalte in die Wissensmodule geh√∂ren.

## Plattform-Workflows

### OpenAI MyGPT & GPT-Store
1. Einen Custom GPT **ZEITRISS [Ver.¬†4.2.2]** erstellen.
2. Einen Pitch mit max. 300¬†Zeichen hinterlegen, z.‚ÄØB. ‚ÄûZeitreise-RPG mit
   Kodex-HUD, explosiven W√ºrfeln und Solo/Coop-Balancing. Keine echten Daten,
   mehr Infos auf https://zeitriss.org/‚Äú.
3. `meta/masterprompt_v6.md` vollst√§ndig in das Masterprompt-Feld kopieren und
   speichern.
4. `README.md`, `master-index.json` sowie alle 18 Runtime-Module (ohne
   Runtime-Stub) in den Wissensspeicher hochladen.
5. Optional den Masterprompt zus√§tzlich im Wissensspeicher sichern, damit
   l√§ngere Sessions stabil bleiben.
6. Den GPT direkt klonen und **ZEITRISS [Ver.¬†4.2.2] beta** nennen.
7. S√§mtliche QA-Sessions ausschlie√ülich im Beta-Klon durchf√ºhren. Die Plattform
   l√§uft online, besitzt aber kein Web-Tool; dokumentiert das Verhalten im
   QA-Log.
8. QA und Publishing erst freigeben, wenn die Chat-Historie keine
   personenbezogenen Daten enth√§lt.
9. Nach bestandener QA den Stand in den Haupt-GPT √ºbertragen und erst danach
   das Store-Listing aktualisieren. Vermerkt die Spiegelung mit Verweis auf den
   QA-Log-Eintrag des gr√ºnen Runs.

### Proton LUMO (verschl√ºsselter Chat)
1. Nach erfolgreicher MyGPT-Abnahme die LUMO-App starten und einen neuen Chat
   √∂ffnen.
2. `meta/masterprompt_v6.md`, `README.md`, `master-index.json` und alle
   Runtime-Module (ohne Runtime-Stub) √ºber die B√ºroklammer hochladen.
3. Optional alle Dateien in den Wissensspeicher √ºbernehmen.
4. Den Masterprompt zus√§tzlich als Chatnachricht einf√ºgen, damit die Rolle zu
   Beginn fixiert ist.
5. Plattform wird aktuell nicht separat optimiert; dokumentiere nur
   Abweichungen, falls LUMO den freigegebenen Stand nicht √ºbernimmt, und
   verlinke sie im QA-Log.

### Lokaler Betrieb (Ollama + OpenWebUI)
1. Nach erfolgreicher MyGPT-Abnahme Ollama mit dem gew√ºnschten Modell
   installieren und OpenWebUI lokal verbinden.
2. Masterprompt, README, Master-Index und alle Runtime-Module importieren
   (Upload oder Wissensbibliothek).
3. Es erfolgen derzeit keine dedizierten lokalen Optimierungen; pr√ºfe nur, ob
   der freigegebene Stand geladen wird, und notiere Abweichungen bei Bedarf im
   QA-Log.

### Spiegelprozess nach QA-Freigabe

1. Pr√ºfe im QA-Fahrplan, dass der relevante Abschnitt als abgeschlossen markiert und mit Commit-ID
   versehen ist.
2. Exportiere den Wissensspeicher aus dem MyGPT-Beta-Klon (Masterprompt, README, master-index und
   Runtime-Module).
3. √úbertrage den Stand unver√§ndert in den produktiven MyGPT und dokumentiere
   Datum sowie QA-Log-Referenz.
4. Spiegele denselben Export im Anschluss auf Store-GPT, Proton LUMO und lokale
   Instanzen in dieser Reihenfolge. Jede Plattform erh√§lt exakt denselben
   Datei-Satz.
5. Erg√§nze im QA-Log einen kurzen Spiegelvermerk (Plattform, Datum,
   verantwortliche Person). Abweichungen werden als neue Findings festgehalten.

### Sync-Checks & Beispielworkflow

- Nach jedem freigegebenen Update best√§tigen, dass MyGPT und Store-GPT denselben
  Stand f√ºhren (Masterprompt, README, Module) und den Release anschlie√üend auf
  LUMO sowie lokal spiegeln.
- Sicherstellen, dass exakt 18 Runtime-Module plus `master-index.json` geladen
  sind; der Runtime-Stub bleibt au√üen vor.
- F√ºr Schnelltests die Checkliste aus
  [Acceptance-Smoke](./qa/tester-playtest-briefing.md#acceptance-smoke-checkliste)
  nutzen und Ergebnisse hier protokollieren.
- Detailablauf f√ºr Uploads siehe Abschnitt ‚ÄûBeispielworkflow‚Äú im README; dort
  stehen die Datei-Checks, die beim Laden kontrolliert werden.

## Go-Live-Checkliste (Build 4.2.2)
Vor der Spiegelung auf produktive Plattformen sind die folgenden Schritte
abzuschlie√üen und im QA-Log zu dokumentieren:

1. **Repository-Pr√ºfungen**
   - `make lint`
   - `make test`
   - `npm run test:hud`
   - `npm run test:debrief`
   - `npm run test:comms`
   Alle L√§ufe m√ºssen ohne Fehler durchlaufen; Warnungen werden im Commit-Log
   vermerkt.
2. **Dokumentationsabgleich**
   - Audit, Fahrplan und Maintainer-Ops auf denselben Stand bringen (Versionen
     pr√ºfen, offene Fragen schlie√üen, QA-Referenzen erg√§nzen).
   - README-Sektion ‚ÄûQA-Artefakte & Nachverfolgung‚Äú auf aktuelle Links testen.
3. **QA-Log & Freigabe**
  - Acceptance-Smoke gegen
    [Acceptance-Smoke](./qa/tester-playtest-briefing.md#acceptance-smoke-checkliste)
    abhaken und den Lauf im QA-Log mit Datum, Plattform und Build-ID
    protokollieren.
   - Offene Punkte im QA-Log schlie√üen oder vertagen (inkl. Verweis auf den
     verantwortlichen Commit).
4. **Spiegelentscheidung**
   - Erst wenn alle obigen Schritte gr√ºn sind, Beta-GPT ‚Üí Produktiv-GPT ‚Üí
     Store-GPT ‚Üí Proton LUMO ‚Üí lokale Instanzen spiegeln.
   - Jede Spiegelung mit Datum, Plattform und QA-Log-Verweis festhalten.

## QA-Loop & Speicherst√§nde
Halte f√ºr QA und Save/Load-Checks den √úbergabeprozess in
`CONTRIBUTING.md#beta-gpt-qa-uebergaben` ein. Erg√§nzend gilt:

### Beta-GPT & Playtests
1. Klone nach jedem Release-Kandidaten den produktiven MyGPT zu
   **ZEITRISS [Ver.¬†4.2.2] beta**.
2. Starte Playtests ausschlie√ülich im Beta-Klon, f√ºge den Auftrag aus
   `docs/qa/tester-playtest-briefing.md` in die erste Chat-Nachricht ein und lasse
   den GPT den kompletten QA-Run ohne weitere Eingriffe simulieren.
3. Pr√ºfe, dass die Antwort die geforderten `ISSUE`-, `L√∂sungsvorschlag`-,
   `To-do`- und `N√§chste Schritte`-Bl√∂cke je Befund enth√§lt, und √ºbertrage sie
   gesammelt und unver√§ndert an Codex (Repo-Agent). Codex erstellt daraus
   Tickets, dokumentiert Freigaben und aktualisiert QA-/Maintainer-Docs.
4. Notiere im QA-Log, welcher Beta-GPT-Prompt verwendet wurde, damit sp√§tere
   Regressionen denselben Ablauf nachvollziehen k√∂nnen.
5. Synchronisiere den Wissensspeicher des produktiven MyGPT sowie weiterer
   Plattformen erst, nachdem Codex die QA als gr√ºn markiert hat.

### √úbergabe an Codex & Dokumentation
1. Exportiere nach jeder Beta-GPT-Session das vollst√§ndige Chatlog (inklusive
   Debug-Ausgaben) und sende es unver√§ndert an Codex. Die vom GPT erzeugten
   `ISSUE`-, `L√∂sungsvorschlag`-, `To-do`- und `N√§chste Schritte`-Bl√∂cke ersetzen
   separate Stichpunktlisten.
2. Markiere im Log klar die Plattform (Standard: MyGPT Beta auf openai.com),
   den Build-Stand und den verwendeten Wissensspeicher.
3. Notiere in deiner √úbergabe, ob Uploads, Save/Load-Checks oder
   Plattformspiegelungen bereits erfolgt sind. Codex √ºbernimmt daraufhin die
   Pflege der Dateien `internal/qa/logs/2025-beta-qa-log.md`,
   `internal/qa/plans/ZEITRISS-qa-fahrplan-2025.md` und
   `internal/qa/audits/ZEITRISS-qa-audit-2025.md` im
   Repo.
4. Nachdem Codex die QA-Dokumente aktualisiert und alle Findings abgearbeitet
   hat, spiegelst du den freigegebenen Stand auf Store-GPT, Proton LUMO und
   lokale Instanzen. Dokumentiere Abweichungen ausschlie√ülich dann, wenn sie
   vom MyGPT-Referenzlauf abweichen.

### Zus√§tzliche QA-Pflichten
1. Plane mindestens drei komplette Durchl√§ufe im MyGPT-Beta ein; weitere
   Plattformen erhalten denselben Stand ohne eigenst√§ndige QA-Schleifen.
2. In jeder Session Save/Load pr√ºfen: `saveGame({...})` ausgeben lassen, lokal
   sichern, neuen Chat √∂ffnen und den Reimport testen.
3. Accessibility-Dialoge (HUD-Erkl√§rung, Offline-Hinweise) und
   HQ-Briefing-Schleifen abgleichen.
4. Acceptance-Smoke-Checklist aus `docs/qa/tester-playtest-briefing.md`
   erg√§nzen und Abweichungen festhalten. Smoketests laufen bei jedem Merge
   automatisch im Repo; dokumentiert erg√§nzende Befunde weiterhin im QA-Log.
5. Falls die GitHub-Action `scripts/smoke.sh` mit einem `ECONNRESET` beim
   Artefakt-Upload scheitert, Job erneut ansto√üen. Der Fehler entsteht beim
   Finalisieren des Uploads und erfordert inhaltlich keine Anpassung am Repo.

### Regressionstest-Zeitplan 2025

- **Q1¬†2025 (19.03.2025 ‚Äì Acceptance-Smoke-Abgleich)**
  - Schwerpunkt: Vollst√§ndiger Regressionstest (Build¬†4.2.2) mit Save/Load.
  - Status: ‚úÖ abgeschlossen.
  - QA-Log: `internal/qa/logs/2025-beta-qa-log.md`, Abschnitt 2025-03-19.
- **Q2¬†2025 (09.‚Äì13.06.2025)**
  - Schwerpunkt: Spiegelprozesse, Save/Load-Regression und Upload-Checks.
  - Status: üóìÔ∏è geplant.
  - QA-Log: Eintrag folgt nach Lauf.
- **Q3¬†2025 (08.‚Äì12.09.2025)**
  - Schwerpunkt: Arena-Gro√üteam-Regression, HUD-Badges und Timer.
  - Status: üóìÔ∏è geplant.
  - QA-Log: Eintrag folgt nach Lauf.
- **Q4¬†2025 (08.‚Äì12.12.2025)**
  - Schwerpunkt: Jahresabschluss-Regression mit Spiegelkontrolle.
  - Status: üóìÔ∏è geplant.
  - QA-Log: Eintrag folgt nach Lauf.

> Aktualisiere Termine bei Verschiebungen unmittelbar im QA-Fahrplan und hier;
> Spiegelplattformen nur nach gr√ºner MyGPT-Abnahme synchronisieren.

## Systemgrenzen (Reminder)
- KI-Spielleitung kann keine Dateien schreiben oder Repos ver√§ndern;
  Speicherst√§nde nur via Copy & Paste.
- Save-Funktionen laufen ausschlie√ülich √ºber das HQ. Missionen lassen sich
  abbrechen, aber nicht zwischen-speichern.
- MyGPT und Store-GPT laufen online ohne Webtool. LUMO bietet
  Ende-zu-Ende-Verschl√ºsselung; Ollama/OpenWebUI bleiben vollst√§ndig offline und
  ohne Webtools.
- DSGVO-konforme Chats sicherstellen: keine realen personenbezogenen Daten
  posten, keine unverschl√ºsselten Log-Transkripte.

## Release-Checkliste
- Versionierung nach **MAJOR.MINOR.PATCH**. `CHANGELOG.md`, `README.md`,
  `master-index.json` und Store-Listing synchron aktualisieren.
- Rechtliche Hinweise pr√ºfen (`docs/trademark.md`, `LICENSE`,
  Markenverweise im README).
- `make lint`, `make test` und `scripts/smoke.sh` ausf√ºhren; Ergebnisse im
  QA-Log vermerken.
- Vor Freigabe sicherstellen, dass auf jeder Plattform exakt 18
  Runtime-Module plus `master-index.json` und Masterprompt vorliegen ‚Äì ohne den
  Runtime-Stub.
- Erst releasen, wenn der Beta-GPT auf MyGPT gr√ºn meldet. Danach Store-GPT
  aktualisieren und den freigegebenen Stand auf LUMO sowie lokal spiegeln. Siehe
  `CONTRIBUTING.md#beta-gpt-qa-uebergaben` f√ºr die √úbergabe an Codex.
